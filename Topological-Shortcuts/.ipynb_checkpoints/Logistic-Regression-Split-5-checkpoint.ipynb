{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b023bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import norm  \n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from random import shuffle\n",
    "from scipy.stats import norm\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from scipy.spatial.distance import squareform\n",
    "import joblib\n",
    "import matplotlib\n",
    "from sklearn.utils import column_or_1d\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "matplotlib.rcParams['font.serif'] = 'Times New Roman'\n",
    "matplotlib.rcParams['font.family'] = \"serif\"\n",
    "matplotlib.rcParams['font.size'] = 15\n",
    "from maximumentropymodels import *\n",
    "import argparse\n",
    "from scipy.spatial.distance import squareform\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import sparse\n",
    "import dask.array as da\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import average_precision_score\n",
    "# logistic regression for feature importance\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "import os.path\n",
    "from scipy import linalg\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95df847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_avg(l1,l2):\n",
    "    l3 = []\n",
    "    for j in range(len(l1)):\n",
    "        l3.append((l1[j]+l2[j])/2)\n",
    "    return l3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a02a1b3",
   "metadata": {},
   "source": [
    "## Load DDI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7723b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv('edge.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False, names=['node1','node2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ddi = nx.from_edgelist(zip(edges['node1'],edges['node2']), create_using=nx.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da324df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(edges, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f21c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train = nx.from_edgelist(zip(train['node1'],train['node2']), create_using=nx.Graph())\n",
    "G_test = nx.from_edgelist(zip(test['node1'],test['node2']), create_using=nx.Graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b22a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train_neg = nx.complement(G_train)\n",
    "G_test_neg = nx.complement(G_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6493262",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_edges_train = sample(list(G_train_neg.edges()),len(train)) \n",
    "negative_edges_test = sample(list(G_test_neg.edges()),len(test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb428979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "negative_edges_train_df = pd.DataFrame()\n",
    "negative_edges_train_df['node1'] = [x[0] for x in negative_edges_train]\n",
    "negative_edges_train_df['node2'] = [x[1] for x in negative_edges_train]\n",
    "\n",
    "negative_edges_test_df = pd.DataFrame()\n",
    "negative_edges_test_df['node1'] = [x[0] for x in negative_edges_test]\n",
    "negative_edges_test_df['node2'] = [x[1] for x in negative_edges_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([train,negative_edges_train_df])\n",
    "train_data['Y'] = [1] * len(train) + [0] * len(negative_edges_train_df)\n",
    "\n",
    "test_data = pd.concat([test,negative_edges_test_df])\n",
    "test_data['Y'] = [1] * len(test) + [0] * len(negative_edges_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53318d",
   "metadata": {},
   "source": [
    "# Sense Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c020182",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_nodes = dict(G_train.degree())\n",
    "clustering_coeff = nx.clustering(G_train)\n",
    "triangle_nodes = dict(nx.triangles(G_train))\n",
    "nn_degree = nx.average_neighbor_degree(G_train)\n",
    "betweenness_cetrality = dict(nx.betweenness_centrality(G_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acfb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature_dict = dict()\n",
    "for node in tqdm(list(G_train.nodes())):\n",
    "    node_feat_list = []\n",
    "    node_feat_list.append(degree_nodes[node])\n",
    "    node_feat_list.append(clustering_coeff[node])\n",
    "    node_feat_list.append(triangle_nodes[node])\n",
    "    node_feat_list.append(nn_degree[node])\n",
    "    node_feat_list.append(betweenness_cetrality[node])\n",
    "    node_feature_dict[node] = node_feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7e293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_feature_edge_list = []\n",
    "for index, row in tqdm(train_data.iterrows()):\n",
    "    train_data_feature_edge_list.append(list_avg(node_feature_dict[row['node1']],node_feature_dict[row['node2']]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b584cff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array(train_data_feature_edge_list)\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "y = np.array(train_data['Y'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2d2998",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "importance = model.coef_[0]\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "plt.figure(figsize=(8, 8),dpi=300)\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef620760",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes = list(set(train_data['node1']).union(set(train_data['node2'])))\n",
    "test_transductive = test_data[test_data['node1'].isin(train_nodes) & test_data['node2'].isin(train_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ec4b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_feature_edge_list = []\n",
    "for index, row in tqdm(test_transductive.iterrows()):\n",
    "    test_data_feature_edge_list.append(list_avg(node_feature_dict[row['node1']],node_feature_dict[row['node2']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25275ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(test_data_feature_edge_list)\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "y = np.array(test_transductive['Y'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dba55e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('AUROC: ', roc_auc_score(y_pred,y))\n",
    "print('AUPRC: ', average_precision_score(y_pred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c5a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
